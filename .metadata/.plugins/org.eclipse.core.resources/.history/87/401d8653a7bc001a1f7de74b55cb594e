/** @file visionManager.c
 *  @brief Functions for managing images/vision.
 *
 *  These functions currently setup the pointers to where the PRU will write image data
 *  and an image data ready flag, process and display the image data from the shared memory
 *  in OpenCV windows, and garbage collect the image data when the program shuts down.
 *  The image ready flag is a cheap way to deal with the fact
 *  that the PRU can write data to the shared memory much faster than the application
 *  processor can consume it. We will want to come up with a better way of working with images
 *  on the application processor side. Image processing is currently just using OpenCV
 *  cvInRangeS function to mask a certain color (aibo ball pink) and cvMoments to identify
 *  instances of it in the image. The initialize function creates two windows, one for the
 *  image and one for the thresholded mask. The main loop updates these windows when the image
 *  ready flag is set.
 *
 *  @author Bill Merryman
 *  @bug No known bugs.
 *
 *  Created on: Nov 19, 2017
 *
 */

#include <iostream>
#include <fstream>
#include "opencv2/imgproc.hpp"
#include "opencv2/highgui.hpp"
#include "opencv2/opencv.hpp"
#include "opencv2/dnn.hpp"
#include "opencv2/dnn/shape_utils.hpp"
#include "visionManager.hpp"

extern "C"
{
#include "PRUInterop.h"
#include "pru.h"
}

using namespace std;
using namespace cv;
using namespace cv::dnn;

volatile int *imageReadyFlag;
cv::Mat displayImage;
cv::Mat processingImage;

Net caffeNet;
Net darknetNet;

int imageProcessingType = 0;

Scalar thresholdLow = Scalar(60, 0, 100);
Scalar thresholdHigh = Scalar(200, 80, 255);
Rect thresholdROI = Rect(135, 95, 50, 50);

float caffeConfidence = 0.0;
float darknetConfidence = 0.0;
float darknetNonMaximaSuppressionThreshold = 0.0;

std::vector<std::string> caffeClasses;
std::vector<std::string> darknetClasses;

std::vector<cv::String> unconnectedOutputLayersNames;

void visionManagerInitialize(const char *caffeNamesFile,
								const char *prototxtFile,
								const char *caffemodelFile,
								float caffeConf,
								const char *darknetNamesFile,
								const char *cfgFile,
								const char *weightsFile,
								float darknetConf,
								float darknetNMSThreshold)
{
	CvSize inputSize;
	inputSize.width = IMAGE_COLUMNS_IN_PIXELS;
	inputSize.height = IMAGE_ROWS_IN_PIXELS;

	PRU_INTEROP_1_DATA* PRUInterop1Data = &(getPRUInteropData()->PRUInterop1Data);

	displayImage = cv::Mat(inputSize, CV_8UC3, (void*)(PRUInterop1Data->imageData));
	processingImage = cv::Mat(inputSize, CV_8UC3);
	imageReadyFlag = ((int *)(&(PRUInterop1Data->imageReadyFlag)));

	caffeNet = cv::dnn::readNet(caffemodelFile, prototxtFile);
	darknetNet = cv::dnn::readNet(weightsFile, cfgFile);

	caffeConfidence = caffeConf;
	darknetConfidence = darknetConf;
	darknetNonMaximaSuppressionThreshold = darknetNMSThreshold;

	visionManagerInitializeCaffe();
	visionManagerInitializeDarknet();

	string nameLine;

	ifstream cnf(caffeNamesFile);
	while (getline(cnf, nameLine)) caffeClasses.push_back(nameLine);

	ifstream dnf(darknetNamesFile);
	while (getline(dnf, nameLine)) darknetClasses.push_back(nameLine);

	cvNamedWindow("Display_Image", CV_WINDOW_AUTOSIZE);
	cvNamedWindow("Processing_Image", CV_WINDOW_AUTOSIZE);
	setWindowTitle("Display_Image", "No Image Processing.");
	setWindowTitle("Processing_Image", "Not Used.");
}

void visionManagerInitializeCaffe()
{

}

void visionManagerInitializeDarknet()
{
        vector<int> unconnectedOutputLayersIndices = darknetNet.getUnconnectedOutLayers();
        vector<String> outputLayersNames = darknetNet.getLayerNames();
        unconnectedOutputLayersNames.resize(unconnectedOutputLayersIndices.size());
        for (size_t i = 0; i < unconnectedOutputLayersIndices.size(); ++i)
        unconnectedOutputLayersNames[i] = outputLayersNames[unconnectedOutputLayersIndices[i] - 1];
}

void visionManagerUninitialize()
{
	cvDestroyWindow("Display_Image");
	cvDestroyWindow("Processing_Image");
}

void visionManagerProcess(char key)
{
	if(*imageReadyFlag == IMAGE_NOT_READY) return;

	if(key=='n')
	{
		imageProcessingType=0;
		setWindowTitle("Display_Image", "No Image Processing.");
		setWindowTitle("Processing_Image", "Not Used.");
	}
	if(key=='t')
	{
		imageProcessingType=1;
		setWindowTitle("Display_Image", "Process Image By Threshold");
		setWindowTitle("Processing_Image", "Image Moments");
	}
	if(key=='k')
	{
		imageProcessingType=2;
		setWindowTitle("Display_Image", "Capture color key for Threshold");
		setWindowTitle("Processing_Image", "Not Used.");
	}
	if(key=='c')
	{
		imageProcessingType=3;
		setWindowTitle("Display_Image", "Process Image By Caffe");
		setWindowTitle("Processing_Image", "Not Used.");
	}
	if(key=='d')
	{
		imageProcessingType=4;
		setWindowTitle("Display_Image", "Process Image By Darknet");
		setWindowTitle("Processing_Image", "Not Used.");
	}

	switch(imageProcessingType)
	{
		case 0:
			visionManagerProcessNone();
			break;
		case 1:
			visionManagerProcessThreshold();
			break;
		case 2:
			visionManagerCaptureThreshold();
			break;
		case 3:
			visionManagerProcessCaffe();
			break;
		case 4:
			visionManagerProcessDarknet();
			break;
	}

	*imageReadyFlag = IMAGE_NOT_READY;
}

void visionManagerProcessThreshold()
{
	double area = 0;
	CvPoint position;
	char outputMessage[50];

	inRange(displayImage, Scalar(60, 0, 100, 0), Scalar(200, 80, 255, 0), processingImage);
	cv::Moments moments = cv::moments(processingImage, false);
	area = moments.m00;
	if (area > 1000000)
	{
		position.x = moments.m10 / area;
		position.y = moments.m01 / area;
		sprintf(outputMessage, "pos: %d, %d", position.x, position.y);
		rectangle(displayImage, cvPoint(position.x - 5, position.y - 5), cvPoint(position.x + 5, position.y + 5), cvScalar(0, 255, 0, 0), 1, 8, 0);
		putText(displayImage, outputMessage, Point(position.x + 10, position.y + 5), CV_FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 0, 0), 2, 8, false);
	}
	setWindowTitle("Display_Image", "Process Image By Threshold");
	setWindowTitle("Processing_Image", "Image Moments");
	imshow("Display_Image", displayImage);
	imshow("Processing_Image", processingImage);
}

void visionManagerProcessDNN()
{
	const Size resized(320, 240);
	Point position;

	char outputMessage[64];

	if(*imageReadyFlag == IMAGE_NOT_READY) return;

	Mat blob = cv::dnn::blobFromImage(displayImage,
										0.007843f,
										resized,
										Scalar(127.5));
	net.setInput(blob);
	Mat detections = net.forward();
	for(int i = 0; i < detections.size[2]; i++)
	{
		int idxConf[4] = {0, 0, i, 2};
		float conf = detections.at<float>(idxConf);

		if(conf > 0.5f)
		{
			int idxCls[4] = {0, 0, i, 1};
			int cls = detections.at<float>(idxCls);

			int leftPercent[4] = {0, 0, i, 3};
			int topPercent[4] = {0, 0, i, 4};
			int widthPercent[4] = {0, 0, i, 5};
			int heightPercent[4] = {0, 0, i, 6};

			position.x = detections.at<float>(leftPercent) * resized.width;
			position.y = detections.at<float>(topPercent) * resized.height;
			int width = (detections.at<float>(widthPercent) * resized.width) - position.x;
			int height = (detections.at<float>(heightPercent) * resized.height) - position.y;

			Rect detection(position.x, position.y, width, height);
			rectangle(displayImage, detection, Scalar(0, 255, 0), 1, 8, 0);
			putText(displayImage, CLASSES[cls], Point(position.x, position.y + 10), CV_FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 255, 0), 2, 8, false);
		}
	}
	setWindowTitle("Display_Image", "Process Image By DNN");
	setWindowTitle("Processing_Image", "Not Used.");
	imshow("Display_Image", displayImage);
	imshow("Processing_Image", processingImage);
}
